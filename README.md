# ğŸ§  Customer Churn Prediction â€” Machine Learning Pipeline  
**Day 19 of the 64-Day Machine Learning Challenge**

This project implements an **end-to-end churn prediction system** using classical machine learning techniques.  
It demonstrates how real businesses can identify customers at risk of leaving by analyzing behavioral, demographic, and service-usage patterns.

The solution includes **data preprocessing**, **feature engineering**, **model training**, **evaluation**, and **artifact saving**, making this a production-ready baseline workflow.

---

## âš™ï¸ 1. Problem Overview

Customer churn refers to the percentage of customers who stop using a product or service.  
Predicting churn helps companies:

- Reduce revenue loss  
- Identify high-risk customers  
- Improve retention strategies  
- Optimize targeted marketing  

This project uses the **Telco Customer Churn dataset** (or an auto-generated demo dataset if missing) to build a churn prediction model.

---

## ğŸ—ï¸ 2. System Architecture

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Raw Input Dataset     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                   Data Preprocessing
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ - Missing value handling                           â”‚
    â”‚ - Categorical encoding (One-Hot / Ordinal)         â”‚
    â”‚ - Numerical scaling                                â”‚
    â”‚ - Train-test split                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                     Model Training
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ - Logistic Regression                              â”‚
    â”‚ - Random Forest Classifier                         â”‚
    â”‚ - Hyperparameter-ready pipeline                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                      Model Evaluation
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ - Accuracy                                         â”‚
    â”‚ - Precision / Recall / F1-score                    â”‚
    â”‚ - Confusion Matrix                                 â”‚
    â”‚ - Feature Importance                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                     Artifact Generation
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ - churn_model.pkl                                   â”‚
    â”‚ - preprocessor.pkl                                   â”‚
    â”‚ - confusion_matrix.png                               â”‚
    â”‚ - feature_importance.png                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ 3. Repository Structure

```
â”œâ”€â”€ run_churn.py               # Main execution script
â”œâ”€â”€ data_utils.py              # Load & preprocess raw data
â”œâ”€â”€ model_utils.py             # Model training logic + wrappers
â”œâ”€â”€ viz_utils.py               # Visualization utilities
â”‚
â”œâ”€â”€ telco_churn.csv            # Dataset (auto-generated if missing)
â”œâ”€â”€ churn_model.pkl            # Saved model
â”œâ”€â”€ preprocessor.pkl           # Saved preprocessing pipeline
â”‚
â”œâ”€â”€ confusion_matrix.png       # Evaluation visualization
â”œâ”€â”€ feature_importance.png     # Feature significance plot
â”‚
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md                  # Project documentation
```

---

## ğŸ§¹ 4. Data Preprocessing Details

The preprocessing pipeline includes:

### **Categorical Variables**
- One-Hot Encoding for multi-class categorical features  
- Ordinal encoding where meaningful order exists  
- Handling of â€œYes/Noâ€ binary fields

### **Numerical Variables**
- StandardScaler applied to continuous columns  
- Automatic detection of numerical columns  
- Outlier-tolerant transformations

### **Trainâ€“Test Split**
- 80/20 split  
- Stratified splitting to preserve churn distribution  

---

## ğŸ¤– 5. Machine Learning Models

The project uses a modular structure allowing quick switching between models:

### **Implemented Models**
- **Logistic Regression**  
- **Random Forest Classifier**

### **Easily Extendable**
You can plug in:

- XGBoost  
- LightGBM  
- CatBoost  
- SVM  
- Neural Networks  

The `train_model()` function handles any scikit-learn compatible model.

---

## ğŸ“Š 6. Evaluation Metrics

After model training, the system generates:

- **Accuracy Score**
- **Precision, Recall, F1-Score**
- **Classification Report**
- **Confusion Matrix Heatmap**
- **Feature Importance Bar Chart**

These results help determine what influences customer churn and how well the model generalizes.

---

## ğŸ“ 7. How to Run the Project

### **1ï¸âƒ£ Install Dependencies**
```
pip install -r requirements.txt
```

### **2ï¸âƒ£ Execute Churn Pipeline**
```
python3 run_churn.py
```

### **3ï¸âƒ£ Outputs Generated**
After running, you will see:

```
churn_model.pkl
preprocessor.pkl
confusion_matrix.png
feature_importance.png
```

---

## ğŸ“ˆ 8. Key Insights from Model

- Categorical service-related fields significantly influence churn  
- Contract type and monthly charges are strong predictors  
- Tenure often negatively correlates with churn  
- Random Forest outperforms Logistic Regression for baseline prediction  

---

## ğŸ§­ 9. Future Improvements

- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)  
- SMOTE balancing for imbalanced churn labels  
- Feature selection using SHAP values  
- Deployment as a FastAPI/Flask web service  
- Monitor live churn probabilities

---

## ğŸ“œ License
MIT License â€” free for personal and commercial use.

---

## ğŸ¤ Contributions
Pull requests and feature suggestions are welcome.